from fastapi import FastAPI, Depends
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from apscheduler.schedulers.background import BackgroundScheduler
import requests
from bs4 import BeautifulSoup
from database import SessionLocal, init_db, Notice
import uvicorn

app = FastAPI()

# CORS ì„¤ì •: React Native ì•± ì ‘ì† í—ˆìš©
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# DB ì„¸ì…˜ ì˜ì¡´ì„±
def get_db():
    db = SessionLocal()
    try: yield db
    finally: db.close()

# [í¬ë¡¤ë§ & ì €ì¥ í•¨ìˆ˜]
def crawl_and_save():
    print("ğŸ”„ í¬ë¡¤ë§ ì‹œì‘...")
    db = SessionLocal()
    url = "https://web.kangnam.ac.kr/menu/f19069e6134f8f8aa7f689a4a675e66f.do"
    
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        items = soup.select('div.tbody > ul > li') or soup.select('.c-board-list li')
        
        for item in items:
            a_tag = item.select_one('dl dt a') or item.select_one('a')
            if a_tag:
                title = a_tag.get_text(strip=True)
                link = "https://web.kangnam.ac.kr" + a_tag.get('href', '')
                
                if "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in title or not title: 
                    continue
                
                # 1. DBì— ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                existing_notice = db.query(Notice).filter(Notice.title == title).first()
                
                if not existing_notice:
                    try:
                        new_notice = Notice(title=title, link=link)
                        db.add(new_notice)
                        # 2. flushë¥¼ í†µí•´ ì„¸ì…˜ ë‚´ìš©ì„ DB íŠ¸ëœì­ì…˜ì— ë¯¸ë¦¬ ë°˜ì˜ (ì¤‘ë³µ ë°©ì§€ í•µì‹¬)
                        db.flush() 
                    except Exception as e:
                        db.rollback() # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ ê±´ë§Œ ì·¨ì†Œ
                        print(f"âš ï¸ ì¤‘ë³µ ê±´ ê±´ë„ˆë›°ê¸°: {title}")
        
        db.commit() # ëª¨ë“  ì²˜ë¦¬ê°€ ëë‚˜ë©´ í•œ ë²ˆì— ì»¤ë°‹
        print("âœ… í¬ë¡¤ë§ ë° ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        db.rollback()
    finally:
        db.close()

@app.on_event("startup")
def startup():
    init_db()
    crawl_and_save() # ì‹œì‘ ì‹œ ì¦‰ì‹œ ì‹¤í–‰
    scheduler = BackgroundScheduler()
    scheduler.add_job(crawl_and_save, 'interval', minutes=60) # 1ì‹œê°„ë§ˆë‹¤ ë°˜ë³µ
    scheduler.start()

# [API ì—”ë“œí¬ì¸íŠ¸]
@app.get("/api/notices")
def read_notices(db: Session = Depends(get_db)):
    return db.query(Notice).order_by(Notice.id.desc()).limit(30).all()

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)